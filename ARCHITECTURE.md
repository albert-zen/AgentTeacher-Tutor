# Architecture

## What This Is

Teacher Agent Notebook â€” AI æ•™å­¦å·¥å…·ã€‚Teacher Agent ç”Ÿæˆç»“æ„åŒ–å­¦ä¹ ææ–™å¹¶é€šè¿‡èŠå¤©è¾…å¯¼å­¦ç”Ÿã€‚ä¸‰æ  UIï¼šæ–‡ä»¶æ ‘ | ç¼–è¾‘å™¨ | èŠå¤©ã€‚

**æ ¸å¿ƒæ„¿æ™¯ï¼šä¸Šä¸‹æ–‡ç¼–æ’å™¨ (Context Orchestrator)** â€” è®©ç”¨æˆ·è‡ªç”±é€‰æ‹©ã€ç¼–è¾‘ã€ç»„åˆä¼ ç»™ LLM çš„ä¸Šä¸‹æ–‡ã€‚ä¸€åˆ‡çš†æ–‡ä»¶ã€‚

## Tech Stack

| Layer | Stack |
|-------|-------|
| Client | React 19 Â· Vite 6 Â· Tailwind 4 Â· react-markdown Â· react-syntax-highlighter |
| Server | Express 5 Â· Vercel AI SDK v6 Â· @ai-sdk/openai |
| LLM | OpenAI-compatible API (DashScope / OpenAI / etc.)ï¼Œè¿è¡Œæ—¶å¯åˆ‡æ¢ |
| Storage | JSON files + Markdown files (no database) |
| Testing | vitest Â· supertest Â· jsdom Â· @testing-library/react Â· 150 tests |
| Monorepo | npm workspaces Â· TypeScript strict Â· ES2022 |

## System Overview

```mermaid
graph TB
    subgraph Client ["Client (React + Vite)"]
        LP[Landing Page<br/>sidebar + settings + draft]
        WS[Workspace<br/>FileTree / Editor / Chat]
        API[api/client.ts<br/>REST + SSE stream]
    end

    subgraph Server ["Server (Express)"]
        SR[routes/session.ts<br/>Session CRUD + SSE Chat]
        FR[routes/files.ts<br/>File CRUD + Settings]
        CA[services/contextAssembler.ts<br/>Context assembly]
        LLM[services/llm.ts<br/>LLM client + tools + config]
        PP[services/profileParser.ts<br/>Profile block parsing]
        FS[services/fileService.ts<br/>Sandboxed file I/O]
        ST[db/index.ts<br/>JSON Store]
    end

    subgraph Data ["data/ (filesystem)"]
        SJ[sessions.json]
        PM[profile.md]
        SP[system-prompt.md]
        SPD[session-prompt-draft.md]
        LC[llm-config.json]
        SD["ğŸ“ {sessionId}/<br/>messages.json Â· guidance.md<br/>session-prompt.md Â· context-config.json<br/>milestones.md Â· ground-truth.md"]
    end

    LP & WS --> API
    API -- "REST + SSE" --> SR & FR
    SR --> CA --> LLM
    CA --> PP
    SR & FR --> ST --> SJ
    FR --> FS
    FS --> SD
    LLM -- "streamText + tools" --> EXT["External LLM API"]
```

## Chat Data Flow

```mermaid
sequenceDiagram
    participant U as User
    participant C as Client
    participant S as Server
    participant CA as ContextAssembler
    participant L as LLM
    participant F as FileService

    U->>C: Send message + [file:1:10] refs
    C->>S: POST /session/:id/chat
    S->>F: Resolve file references
    S->>CA: assembleContext(dataDir, sessionId)
    CA-->>S: systemPrompt + profileBlocks
    S->>S: Build message history
    S->>L: streamText(system + messages + tools)

    loop Tool calls (max 10 steps)
        L-->>S: tool-call (read_file / write_file)
        S->>F: Execute tool
        F-->>S: Result
        S-->>C: SSE: tool-call â†’ tool-result
        C->>C: refreshFiles()
    end

    L-->>S: text-delta (streaming)
    S-->>C: SSE: text-delta â†’ done
    C->>C: Render message + refresh UI
```

## Data Model

```mermaid
erDiagram
    SESSION ||--o{ MESSAGE : contains
    SESSION ||--o{ FILE : "has files"
    SESSION {
        string id PK
        string concept
        string createdAt
    }
    MESSAGE {
        string id PK
        string sessionId FK
        string role "user | assistant"
        string content
        array references "optional"
        array toolEvents "optional"
        array parts "optional"
    }
    FILE {
        string path PK
        string content
        int totalLines
    }
```

**Session ä¿æŒè–„** â€” `{ id, concept, createdAt }` ä¸‰ä¸ªå­—æ®µï¼Œæ°¸ä¸è†¨èƒ€ã€‚æ‰€æœ‰ä¸°å¯Œåº¦æ¥è‡ª session ç›®å½•ä¸‹çš„æ–‡ä»¶ï¼š

```
data/
â”œâ”€â”€ profile.md                  # ç”¨æˆ·æ¡£æ¡ˆï¼ˆæŒ‰ # æ ‡é¢˜åˆ†å—ï¼‰
â”œâ”€â”€ system-prompt.md            # å…¨å±€ç³»ç»Ÿæç¤ºè¯
â”œâ”€â”€ session-prompt-draft.md     # æ•™å­¦æŒ‡ä»¤è‰ç¨¿ï¼ˆæ–° session è‡ªåŠ¨å¤åˆ¶ï¼‰
â”œâ”€â”€ llm-config.json             # LLM è¿è¡Œæ—¶é…ç½®ï¼ˆenv fallbackï¼‰
â”œâ”€â”€ sessions.json               # session ç´¢å¼•
â”‚
â””â”€â”€ {sessionId}/
    â”œâ”€â”€ messages.json            # èŠå¤©å†å²
    â”œâ”€â”€ session-prompt.md        # session çº§æ•™å­¦æŒ‡ä»¤ï¼ˆè¿½åŠ åˆ° promptï¼‰
    â”œâ”€â”€ context-config.json      # ä¸Šä¸‹æ–‡é€‰æ‹©é…ç½®
    â”œâ”€â”€ guidance.md              # Teacher æ•™å­¦æŒ‡å—
    â”œâ”€â”€ ground-truth.md          # çŸ¥è¯†æ–‡æ¡£
    â”œâ”€â”€ milestones.md            # å­¦ä¹ è¿›åº¦ (- [x] / - [ ])
    â””â”€â”€ ...                      # ä»»æ„æ–‡ä»¶
```

## Design Principles

| Principle | Implementation |
|-----------|---------------|
| **Everything is a file** | å­¦ä¹ ææ–™ã€profileã€promptã€config éƒ½æ˜¯å¯ç¼–è¾‘æ–‡ä»¶ |
| **Agent è§£è€¦** | `toolEvents`/`parts` ä¸ºå¯é€‰å­—æ®µã€‚æ—  LLM æ—¶é€€åŒ–ä¸ºçº¯ç¬”è®°å·¥å…· |
| **æ²™ç®±å®‰å…¨** | FileService è·¯å¾„éå†é˜²æŠ¤ï¼Œæ‰€æœ‰æ“ä½œé™åˆ¶åœ¨ session ç›®å½•å†… |
| **æµå¼ä¼˜å…ˆ** | å…¨ç¨‹ SSEï¼Œå®¢æˆ·ç«¯å®æ—¶æ¸²æŸ“æ–‡æœ¬å¢é‡å’Œå·¥å…·äº‹ä»¶ |
| **Thin handles, rich files** | Session æ˜¯ç›®å½•æŒ‡é’ˆï¼Œæ–‡ä»¶æ˜¯å†…å®¹ï¼Œä¸å¾€ Session å¡å­—æ®µ |
| **è¿è¡Œæ—¶å¯é…** | LLM config å­˜æ–‡ä»¶ï¼Œè¿è¡Œæ—¶åˆ‡æ¢æ— éœ€é‡å¯ |

## API Endpoints

| Method | Path | Purpose |
|--------|------|---------|
| GET | `/api/session` | List sessions |
| POST | `/api/session` | Create sessionï¼ˆè‡ªåŠ¨å¤åˆ¶ draft â†’ session-promptï¼‰ |
| GET | `/api/session/:id` | Get session + messages |
| POST | `/api/session/:id/chat` | SSE streaming chat |
| GET | `/api/session/:id/milestones` | Milestone progress |
| GET | `/api/session/:id/context-preview` | Preview assembled context |
| PUT | `/api/session/:id/context-config` | Save context selection config |
| GET | `/api/:sid/files` | List session files |
| GET | `/api/:sid/file?path=` | Read file |
| PUT | `/api/:sid/file` | Write file |
| DELETE | `/api/:sid/file?path=` | Delete file |
| GET/PUT | `/api/profile` | User profile |
| GET | `/api/profile/blocks` | Parsed profile blocks |
| GET/PUT | `/api/system-prompt` | Custom system prompt |
| GET/PUT | `/api/session-prompt-draft` | Session prompt template |
| GET | `/api/llm-status` | LLM config status (read-only) |
| PUT | `/api/llm-config` | Update LLM config at runtime |

---

## Context Assembly (å½“å‰çŠ¶æ€)

`contextAssembler.ts` ç›®å‰è¦†ç›– DESIGN.md 5 é˜¶æ®µæµæ°´çº¿çš„ Stage 1-2ã€‚Stage 3-5 ä»åœ¨ `session.ts` è·¯ç”±å†…è”ã€‚

```mermaid
graph LR
    subgraph Assembler ["contextAssembler.ts (Stage 1-2)"]
        S1["1. Resolve Sources<br/>global + session prompt"]
        S2["2. Select Blocks<br/>profile åˆ†å— + è¿‡æ»¤"]
    end

    subgraph Inline ["session.ts è·¯ç”±å†…è” (Stage 3-5)"]
        S3["3. Merge Refs<br/>è§£æ file:s:e å¼•ç”¨"]
        S4["4. Format<br/>æ„å»º ModelMessage[]"]
        S5["5. Emit<br/>è°ƒç”¨ streamText"]
    end

    S1 --> S2 --> S3 --> S4 --> S5

    style Assembler fill:#10b981,color:#fff
    style Inline fill:#a1a1aa,color:#fff
```

**ä¸‹ä¸€æ­¥**ï¼šå°† Stage 3-5 ä»è·¯ç”±ä¸­æå–åˆ° assembler/compilerï¼Œä½¿è·¯ç”±å˜æˆè–„èƒ¶æ°´å±‚ã€‚è¯¦è§ DESIGN.mdã€‚

---

## Architecture Evolution

```
Phase 1 â€” åŸºç¡€ç¼–æ’ âœ…
  âœ… System Prompt æ–‡ä»¶åŒ– + session çº§è¿½åŠ 
  âœ… Session prompt draft æ¨¡æ¿ â†’ æ–° session è‡ªåŠ¨å¤åˆ¶
  âœ… LLM è¿è¡Œæ—¶é…ç½®åˆ‡æ¢
  âœ… Profile åˆ†å—è§£æ + é€‰æ‹©æ€§æ³¨å…¥
  âœ… Context Assembler æ ¸å¿ƒ (Stage 1-2)
  âœ… Session æ ‡é¢˜è‡ªåŠ¨æ‘˜è¦

Phase 2 â€” å¯è§çš„ä¸Šä¸‹æ–‡ (next)
  â†’ Context Assembler å®Œæ•´åŒ– (Stage 3-5 æå–)
  â†’ ä¸Šä¸‹æ–‡é¢„è§ˆé¢æ¿ UIï¼ˆæ¨¡å‹çœ‹åˆ°äº†ä»€ä¹ˆï¼‰
  â†’ Profile å—é€‰æ‹©æ¥å…¥ context-config
  â†’ è·¨ session æ–‡ä»¶å¼•ç”¨

Phase 3 â€” å®Œæ•´ç¼–æ’
  â†’ Part Accumulator å…±äº«æå–
  â†’ èŠå¤©å†å²æ–‡ä»¶åŒ– + Fork
  â†’ å¤šæ¨¡æ€è¾“å…¥ï¼ˆå›¾ç‰‡/è§†è§‰ï¼‰
  â†’ Agent è”ç½‘æœç´¢ â†’ ç»“æœå½’æ¡£ä¸ºæ–‡ä»¶
```
